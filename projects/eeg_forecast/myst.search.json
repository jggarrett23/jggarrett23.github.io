{"version":"1","records":[{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)"},"type":"lvl1","url":"/dmd","position":0},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)"},"content":"In this section, we forecast EEG activity using a DMD model, which extracts the dominant spatiotemporal modes of a system by finding the best-fit linear operator that evolves the signal forward in time. This algorithm can be conceputalized as a combination of the dimensionality reduction of PCA with the spectral analysis of a Fourier Transform, making it well suited for capturing state changes in neural activity.\n\n","type":"content","url":"/dmd","position":1},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl3":"Background"},"type":"lvl3","url":"/dmd#background","position":2},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl3":"Background"},"content":"\n\nDMD is a powerful factorization and dimensionality reduction technique designed for sequential data containing complex (non)linear dynamics (Schmid, 2022). At its core, it decomposes a univariate or multivariate time series into a set of interpretable spatial modes and scalar amplitudes that describe its spectral properties. When linearly combined, these parameters reconstruct the original signal and allow us to project the system’s state into the future.\n\nIn contrast to traditional dynamical system models, DMD does not attempt to extract governing equations by linearizing perturbations near an equilibrium point. Instead, it draws from Koopman operator theory and treats the data as a finite-dimensional “snapshot” of an underlying infinite-dimensional system, finding the best linear operator that captures the temporal evolution of these observables.\n\n","type":"content","url":"/dmd#background","position":3},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl4":"Representing EEG Activity as a Dynamical System","lvl3":"Background"},"type":"lvl4","url":"/dmd#representing-eeg-activity-as-a-dynamical-system","position":4},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl4":"Representing EEG Activity as a Dynamical System","lvl3":"Background"},"content":"Let y_t \\in \\mathbb{R}^m represent the state of m EEG channels at time t. DMD assumes that the “snapshot” y_t is connected to the next snapshot y_{t+1} by a linear mapping:y_{t+1} = \\textbf{A}y_t \\tag{1}\n\nwhere \\textbf{A} \\in \\mathbb{R}^{m \\times m} describes the dynamics of the system. In an EEG experiment, measurements of this state are sampled at regular intervals of \\Delta t.\n\nTo solve for \\mathbf{A} using a data-driven approach, we gather a sequence of k snapshots in time into the matrix \\mathbf{X}. This matrix is then split into two m \\times (k-1) matrices:\n\n$$\\begin{align*}\n\n\\mathbf{X}_1 &= \\begin{bmatrix}\n\\vert & \\vert & & \\vert \\\\\ny_0 & y_1 & \\cdots & y_{k-1} \\\\\n\\vert & \\vert & & \\vert \n\\end{bmatrix},  \\\\\\\\\n\n\\mathbf{X}_2 &= \\begin{bmatrix}\n\\vert & \\vert & & \\vert \\\\\ny_1 & y_2 & \\cdots & y_{k} \\\\\n\\vert & \\vert & & \\vert \n\\end{bmatrix}. \\tag{2}\n\n\\end{align*}\n\n$$\n\nHere, \\mathbf{X}_2 is simply the matrix \\mathbf{X}_1 shifted forward by one \\Delta t. Following the logic of Equation (1), the linear operator \\mathbf{A} can be approximated by minimizing error in the following relationship:\\begin{align*}\n\\mathbf{X}_2 &= \\mathbf{A}\\mathbf{X}_1 \\\\\n\\mathbf{A} &= \\mathbf{X}_2 \\mathbf{X}_1^{\\dagger} \\tag{4}\n\\end{align*}\n\nwhere ^{\\dagger} is the Moores-Penrose pseudoinverse.\n\n","type":"content","url":"/dmd#representing-eeg-activity-as-a-dynamical-system","position":5},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl4":"DMD Algorithm","lvl3":"Background"},"type":"lvl4","url":"/dmd#dmd-algorithm","position":6},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl4":"DMD Algorithm","lvl3":"Background"},"content":"Often, the snapshot matrix \\mathbf{X}_1 is high-dimensional, making its Moore-Penrose pseudoinverse computationally expensive to calculate directly. This is a common hurdle in EEG research, where recordings from 64 to 128 electrodes create wide snapshot matrices. To circumvent this, we utilize the Singular Value Decomposition (SVD) to project the data into a lower-dimensional subspace:\\mathbf{X}_1 = U \\Sigma V^{*}\n\nwhere U \\in \\mathbb{R}^{m \\times m} contains the spatial components, \\Sigma \\in \\mathbb{R}^{m \\times (k-1)} contains the singular values, V^{*} \\in \\mathbb{R}^{(k-1) \\times (k-1)} contains the temporal components, and ^{*} denotes the complex conjugate transpose.\n\nTo filter noise and reduce complexity, we truncate these matrices based on the singular value threshold r:\\mathbf{X}_1 \\approx U_r \\Sigma_r V^*_r\n\nwhere U_r \\in \\mathbb{R}^{m \\times r}, \\Sigma_r \\in \\mathbb{R}^{r \\times r}, and V_r^* \\in \\mathbb{R}^{r \\times (k-1)}. While several methods exist for choosing r, the Gavish and Donoho (2014) algorithm provides an optimal hard threshold for matrices containing noise. By working in this reduced space, we can compute a low-rank approximation of the dynamics \\mathbf{\\tilde{A}} \\in \\mathbb{R}^{r \\times r} much more efficiently:\\mathbf{\\tilde{A}} \\approx U^*_r \\mathbf{X}_2 V_r \\Sigma_r^{-1}  \\tag{5}\n\nOnce we have \\mathbf{\\tilde{A}}, we perform an eigendecomposition to derive the dynamic modes and eigenvalues of the system:\\begin{align*}\n\\mathbf{\\tilde{A}} \\mathbf{W} &= \\mathbf{W} \\mathbf{\\Lambda} \\\\\n\\mathbf{\\Phi} &= \\mathbf{X}_2 V_r \\Sigma_r^{-1} W \\tag{6}\n\\end{align*}\n\nwhere \\mathbf{W} is a matrix of eigenvectors, \\mathbf{\\Phi} is a matrix whose columns are the DMD modes \\phi_i, and \\mathbf{\\Lambda} is a diagonal matrix containing the DMD eigenvalues \\lambda_i that represent the growth/decay rates for each \\phi_i. Note, the eigenvalues of \\mathbf{A} and \\mathbf{\\tilde{A}} are equivalent and the eigenvectors are related via a linear tranform (Schmid, Meyer, & Pust, 2009; Proctor, Brunton, & Kutz, 2014).\n\nTo turn the DMD modes back into a time series, we first determine the initial weight or amplitude \\xi using the initial state y_1 and \\mathbf{\\Phi}:\\begin{align*}\n\\xi &= \\mathbf{\\Phi}^\\dagger y_0 \\tag{7}\n\\end{align*}\n\nThe temporal evolution of these modes is captured by a Vandermonde matrix (\\mathbf{C}), which applies the eigenvalues \\lambda_i across time steps:\\mathbf{C} = \\begin{bmatrix}\n1 & \\lambda_1 & \\lambda_2^2 & \\cdots & \\lambda_1^{k-1} \\\\\\\\\n1 & \\lambda_2 & \\lambda_2^2 & \\cdots & \\lambda_2^{k-1} \\\\\n\\vdots & \\vdots & \\vdots & & \\vdots \\\\\n1 & \\lambda_r & \\lambda_r^{2} & \\cdots & \\lambda_r^{k-1}\n\\end{bmatrix}\n\nFinally, we reconstruct an approximation of the original snapshot matrix \\mathbf{\\hat{X}} as the product of the modes, their amplitudes, and their temporal evolution:\\mathbf{\\hat{X}} = \\mathbf{\\Phi} \\text{diag}(\\xi) \\mathbf{C} \\tag{8}\n\nBecause \\mathbf{C} is a function of the discrete time step k, forecasting the next h snapshots is accomplished by extending the Vandermonde matrix and adding columns for k, k+1, \\dots, k+h.\n\n","type":"content","url":"/dmd#dmd-algorithm","position":7},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl4":"Link between DMD and Koopman Operator Theory","lvl3":"Background"},"type":"lvl4","url":"/dmd#link-between-dmd-and-koopman-operator-theory","position":8},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl4":"Link between DMD and Koopman Operator Theory","lvl3":"Background"},"content":"Standard DMD focuses on estimating a linear mapping between snapshots of the raw EEG signal y. However, this linear mapping is likely a poor representation of the temporal evolution of neural states that progress in a nonlinear fashion:y_{t+1} = \\mathcal{F}(y_t)\n\nwhere \\mathcal{F} represents the nonlinear governing equations of the system. This mapping often stems from the discretization of partial differential equations that describe key features of state changes in neural activity, and identifying \\mathcal{F} directly from noisy EEG data is challenging. Koopman analysis provides a data-driven approach to uncover these governing equations by tracing observables of y, which we denote as g(y), as they evolve in time (Schmid et al., 2022).\n\nObservables represent a projection of the state vector onto a new manifold using a set of potentially infinite-dimensional functions g(\\cdot). This process, known as “lifting”, embeds y into a space in which its change between time points is linear:g(y_{t+1}) = \\mathcal{K}g(y_t)\n\nwhere \\mathcal{K} is called the Koopman operator. In this framework, we trade finite-dimensional nonlinear complexity for infinite-dimensional linear simplicity.\n\nThe true utility of the Koopman operator lies in its spectral decomposition. Just as we performed eigendecomposition on the autoregressive matrix \\mathbf{A}, we can analyze the eigenvalues of the Koopman operator. These spectral components can be estimated by performing DMD on snapshot matrices containing the observables g(y)—an approach known as Exact DMD (Tu et al., 2014). By shifting our focus from the raw EEG signal to these observables, we gain a more robust window into the underlying neural dynamics. However, for these numerical results to be meaningful, the data must be linearly consistent. This means the set of observables we choose must be “rich” enough to span a subspace that remains invariant under the action of the Koopman operator. When this condition is met, the DMD modes and eigenvalues closely approximate their true Koopman counterparts. Ultimately, Koopman operator theory provides a framework for uncovering a set of modes, amplitudes, and eigenvalues that describe complex nonlinear dynamics of a system.\n\n","type":"content","url":"/dmd#link-between-dmd-and-koopman-operator-theory","position":9},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl4":"Hankelization","lvl3":"Background"},"type":"lvl4","url":"/dmd#hankelization","position":10},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl4":"Hankelization","lvl3":"Background"},"content":"A significant challenge in the application of Exact DMD to model a dynamical system is creating a “sufficiently rich” dictionary of observables whose subspace accurately approximates a set of Koopman modes, eigenfunctions, and eigenvalues (Williams, Rowley, & Kevrekids, 2015). Common lifting methods include Hermite polynomials, radial basis functions, discontinuous spectral elements, kernel functions, and deep learning networks (Li et al., 2017; Williams, Rowley, & Kevrekids, 2015; Curtis et al., 2023). One popular approach is to constructing augmented snapshot matrices by appending (h-1) time-delayed measurements:\\mathbf{X}_{1}^{aug} = \\begin{bmatrix}\n\\vert & \\vert &  & \\vert \\\\\ny_0 & y_1 & \\cdots & y_{k-h} \\\\\n\\vert & \\vert &  & \\vert \\\\\n\\vert & \\vert &  & \\vert \\\\\ny_1 & y_2 & \\cdots & y_{k-h+1} \\\\\n\\vert & \\vert &  & \\vert \\\\\n& & \\vdots &  & \\\\\n\\vert & \\vert &  & \\vert \\\\\ny_h & y_h+1 & \\cdots & y_{k-1} \\\\\n\\vert & \\vert &  & \\vert\n\\end{bmatrix}\n\nThe same augmentation is applied to \\mathbf{X}_2 to construct \\mathbf{X}_{2}^{aug}. hese augmented snapshot matrices have a Hankel structure, often referred to as time-delay embeddings. This approach yields an intrinsic coordinate system that is hypothesized to form an approximate invariant subspace for the Koopman operator. By increasing the dimensionality through these temporal delays, we allow the linear DMD algorithm to resolve complex, nonlinear dependencies that are typically invisible in a single, raw snapshot.\n\nCrucially, this methodology is mathematically robust for ergodic systems (Arbabi & Mezic, 2017). For systems that explore their entire available state space over time, delay embeddings provide a reliable way to recover the true spectral properties of the Koopman operator from measurements alone. For EEG forecasting, this means the historical memory contained in the Hankel matrix allows the model to reconstruct the broader dynamical landscape of the brain and project state changes forward with significantly higher fidelity. Indeed, prior work has shown that applying DMD to hankelized snapshot matrices successfully reconstructs snapshot matrices and produces a DMD mode spectrum that parallels spectral analysis using a discrete Fourier transform (Brunton et al., 2016).\n\nAlthough using hankelization simplifies the process of constructing a sufficiently rich set of observables, it still requires identification of an optimal time delay h. Takens’ embedding theorem advises that Hankel matrices have a minimum of (2d+1) rows in order to unfold a d-dimensional attractor into a space where its topology is presevered, yet this requires a priori knowledge of the attractor’s structure. Instead, we will use a simple grid search to identify a delay that minimizes the reconstruction error (e.g., \\left\\|\\mathbf{X} - \\mathbf{\\hat{X}}\\right\\|^{2} ).\n\n","type":"content","url":"/dmd#hankelization","position":11},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl3":"Implementing DMD"},"type":"lvl3","url":"/dmd#implementing-dmd","position":12},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl3":"Implementing DMD"},"content":"\n\nNow lets put theory into practice. There are some open-source packages for implementing DMD and its various adaptations in a computationally efficient manner (e.g., \n\nPyDMD), but we are going to use custom code to gain a deeper intuition into how the algorithm works.\n\nimport numpy as np\nimport scipy.linalg as linalg\nimport matplotlib.pyplot as plt\nfrom utils import OptimalSVHT\nfrom tqdm import trange\n\n\n\nFirst we will define a class for the DMD model. Following scikit-learn best practices, we are going to implement fit, predict, and score methods incase we want to use a built-in optimization algorithm.\n\nclass DMD:\n\n    def __init__(self, dt, time_delay=0, svd_threshold='optimal', scale_modes=False, clip_lambda=False):\n        \"\"\"\n        Dynamic Mode Decomposition (DMD).\n        \n        Parameters:\n        - dt: Sampling period (1/Fs).\n        - time_delay: Number of 'memory' stacks for Hankelization (h). \n                      Setting time_delay > 0 lifts the data with Hankel and implements the Extend DMD algorithm default=0 (no delays).\n        - svd_threshold: Strategy to truncate noise ('optimal', cumulative float, or None).\n        - scale_modes: If True, balances the A matrix using singular values.\n        - clip_lambda: If True, forces eigenvalues into the unit circle for stability.\n        \"\"\"\n        super().__init__()\n\n        self.dt = dt\n        self.svd_threshold=svd_threshold \n        self.scale_modes = scale_modes\n        self.clip_lambda = clip_lambda\n        self.time_delay = time_delay \n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fits the DMD model to the data matrix X.\n        X shape: (n_channels, n_snapshots)\n        \"\"\"\n\n        # Store original dimensions\n        m, k = X.shape\n\n        self.m = m\n        self.k = k\n\n        # Hankelization\n        if self.time_delay:\n            X = self.time_delay_embedding(X, self.time_delay)\n\n        # Split data\n        X1, X2 = X[:, :-1], X[:, 1:]\n            \n\n        # Get shape of matrices after hankel and split\n        m, k = X1.shape\n\n        # Decompose X1 \n        U, s, Vh = linalg.svd(X1, full_matrices=False)\n        V = Vh.conj().T\n        S = np.diag(s)\n\n        # Save unthresholded singular values\n        self.singular_values = s\n\n        # Reduce dimensionality of the data\n        svd_threshold = self.svd_threshold\n\n        if svd_threshold == 'optimal':\n            # use optimal svd threshold if a threshold has not been provided\n            beta_ratio = m / k\n            if beta_ratio > 1:\n                beta_ratio = 1/beta_ratio\n\n            thresholder = OptimalSVHT(sigma_known=False) # based on Gavish & Donoho (2014)\n            \n            thresh = thresholder.compute_optimal_SVHT_coef(beta_ratio)* np.median(s)\n            r = (S > thresh).sum().astype(int)\n\n        elif isinstance(svd_threshold, float) and 0 < svd_threshold < 1:\n            # use cumlative energy\n            s_squared = s**2\n            cumulative_energy = np.cumsum(s_squared) / (np.sum(s_squared))\n            r = np.argmax(cumulative_energy > svd_threshold) + 1\n\n        elif svd_threshold == None:\n            # keep all of the singular values\n            r = U.shape[-1]\n\n        # store rank for traceability\n        self.svd_rank = r\n\n        # Truncate\n        U_r = U[:, :r]\n        V_r = V[:, :r]\n        S_r = S[:r, :r]\n\n        # Estimate A matrix\n        A = U_r.conj().T @ X2 @ V_r @ linalg.inv(S_r) \n\n        if self.scale_modes:\n           # scale modes by singular values to get corresponding energy for DMD spectrum (Brunton et al., 2016)\n           A = np.diag(np.diag(S_r)**(-1/2)) @ A @ np.diag(np.diag(S_r)**(1/2))\n\n        # eigen decomposition\n        lamda, W = linalg.eig(A)\n\n        # clip eigenvalues to unit circle for stability\n        if self.clip_lambda:\n            self.lamda_uncliped = lamda\n            max_mag = 1.0\n            lamda_clipped = np.where(np.abs(lamda) > max_mag, lamda/np.abs(lamda)*max_mag, lamda)\n            lamda = lamda_clipped\n        \n        if self.scale_modes:\n            W = S_r**(1/2) @ W\n\n        # Estimate DMD modes\n        Phi = X2 @ V_r @ linalg.inv(S_r) @ W\n\n        # Estimate amplitudes\n        b = linalg.pinv(Phi) @ X1[:, 0]\n\n        # Truncate Phi if used hankel and keep original m rows\n        Phi = Phi[:self.m,:]\n        \n        # store modes, amplitudes, and eigenvalues\n        self.modes = Phi\n        self.eigs = lamda\n        self.amplitudes = b\n        self.omega = np.log(lamda) / self.dt\n        self.mode_hz = abs(np.imag(self.omega)/2/np.pi)\n\n        return self\n\n    def predict(self, start=0, end=None):\n        \"\"\"\n        Reconstructs and/or forecast the time series using the learned DMD modes.\n        -start: start index\n        -end: end index. If None, then reconstructs original time series (default=None)\n        \"\"\"\n        if end is None:\n            end = self.k\n        \n        # construct vandermode matrix\n        t_pows = np.tile(\n            np.arange(start, end),\n            (self.amplitudes.shape[0], 1)\n            )\n        \n        C = self.eigs[:, np.newaxis] ** t_pows\n\n        # time dynamics\n        Z = np.diag(self.amplitudes) @ C\n\n        self.time_dynamics = Z\n\n        # reconstruct original data\n        X_hat = (self.modes @ Z).real\n    \n        return X_hat\n    \n    def score(self, X, y=None):\n        \"\"\"\n        Evaluates reconstruction accuracy using Mean Squared Error (MSE).\n        \"\"\"\n        X_hat = self.predict(start=0, end=X.shape[-1])\n        mse = np.mean((X - X_hat)**2)\n        return mse\n\n    @staticmethod\n    def time_delay_embedding(X, h):\n        \"\"\"\n        Performs Hankelization by stacking time-delayed snapshots.\n        X: array of shape (m, k)\n        h: number of delays\n        Returns: array of shape (m*h, k-h+1)\n        \"\"\"\n\n        m, k = X.shape\n\n        if h > k:\n            raise ValueError(\"h must be <= number of time steps\")\n\n        delayed = [X[:, i:k-h+i+1] for i in range(h)]\n        X_aug = np.vstack(delayed)\n\n\n        return X_aug\n\n\n\nGreat! Now we are going to apply this to our EEG data. As a brief recap, this data comes from a study mapping steady state visual evoked potentials (SSVEPs) across various frequency bands (Gu et al., 2024). This makes it perfect for DMD, since SSVEPs contain a strong oscillatory component. For this analysis, we will focus on a single trial during which the presented stimulus flickered at 10 Hz.\n\n# load single subject from Gu et al., 2024 SSVEP experiment\n# Note, data has been downsampled to 250 Hz\ndata = np.load('../Data/Gu et al., 2024/data_s1_64_down.npy')\n\n\n\n# block x stimulation frequency x time x channels x conditions (i.e., modulation depths; low and high luminance ratios)\n# stimulation frequencies are from 1-60 in increments of 1 Hz\nnBlocks, nFreqs, nTime, nChans, nCons = data.shape\n\n# extract a single set of time series for 10 Hz stimulation\n# transpose to make channels x time\ntrial_idx = 0\nstim_idx = 9\nX = data[trial_idx, stim_idx, :, :, 1].T\n\n# SSVEPs are typically localized over the P-PO-O electrodes \nssvep_chan_names = ['Pz', 'PO5', 'PO3', 'POz', 'PO4', 'PO6', 'O1', 'Oz', 'O2']\nssvep_chans_idx = [48,54,55,56,57,58,61,62,63]\n\nssvep_chans_dict = dict(zip(ssvep_chan_names, ssvep_chans_idx))\n\n\n\n# construct time vector. Stimulation time is 5s, and epochs included 0.14s post stimulus offset\nFs = 250.\nt = np.arange(0, 5.14, 1/Fs) * 1000\n\n\n\nNow lets visualize the data to get a sense of its structure (i.e., trend, seasonality, non-stationarity, etc.):\n\nplt.figure(figsize=(7,4))\nplt.plot(t, X[ssvep_chans_dict['Oz'], :], color='k', alpha=0.5)\nplt.xlabel('Time (ms)')\nplt.ylabel(r'Voltage ($\\mu V$)')\nplt.title('Oz')\nplt.show()\n\n\n\nLooking at activity from a single electrode, we see immediately it is non-stationarity and contains a steep linear trend. While DMD can technically process this data, it is built on an autoregressive framework that assumes the underlying rules of the system remain constant over time. A linear trend acts as a ‘moving target’ for the algorithm, forcing it to waste its energy modeling a shifting baseline rather than the actual oscillatory components we want to isolate.\n\nLets remove the linear trend:\n\n# Construct design matrix using time as a covariate w/ an intercept\ntime_design_matrix = np.vstack([np.ones(nTime), np.arange(nTime)])\n\n\n\n# Estimate the trend. Using custom code incase we want to add the trend back in later\nbeta, _, _, _ = linalg.lstsq(time_design_matrix.T, X.T)\ntrend = (time_design_matrix.T @ beta).T\n\n\n\n# Detrend the time series\nX_detrended = X - trend\n\n\n\n# Visualize Raw vs Trend\nplt.figure(figsize=(7,4))\nplt.plot(t, X[ssvep_chans_dict['Oz'], :], color='k', alpha=0.4)\nplt.plot(t, trend[ssvep_chans_dict['Oz'], :], color='r', linestyle='--', label='Estimated Trend')\nplt.xlabel('Time (ms)')\nplt.ylabel(r'Voltage ($\\mu V$)')\nplt.title('Oz')\nplt.legend(frameon=False)\nplt.show()\n\n\n\n# Demean and scale the data for SVD (similar to PCA)\nX_centered = (X_detrended - X_detrended.mean(axis=-1, keepdims=True)) / X_detrended.std(axis=-1, keepdims=True)\n\n\n\n# construct the model\ndmd = DMD(\n    dt=1/Fs, \n    scale_modes=True, \n    clip_lambda=True, \n    svd_threshold=0.999\n)\n\n\n\nNext we are going to perform a grid search for the optimal delay. Though the object is compatible with scitkit-learn optimization algorithms, we will just use a simple for loop tracking AIC, BIC, SVD rank, and reconstruction MSE:\n\n# Define bounds of time delays to search over\ntime_delays = np.arange(50,300,10)\nnDelays = len(time_delays)\n\n\n\nreconstruction_errors = np.zeros(nDelays)\naics = np.zeros(nDelays)\nbics = np.zeros(nDelays)\nranks = np.zeros(nDelays)\ntotal_observations = X_centered.size\nfor i in trange(nDelays):\n    dmd.time_delay = time_delays[i]\n\n    dmd.fit(X_centered)\n    mse = dmd.score(X_centered)\n\n    nModes = dmd.modes.shape[0]\n    # track rank to check if model is capturing more noise as delays increase, or if rank is roughly the same\n    ranks[i] = dmd.svd_rank\n    n_free_parameters = nModes * (2 * nChans + 1)\n\n    # compute information criterion metrics to ensure not overfitting\n    aic = 2*n_free_parameters + total_observations * np.log(mse)\n    bic = n_free_parameters * np.log(total_observations) + total_observations * np.log(mse)\n\n    reconstruction_errors[i] = mse\n    aics[i] = aic\n    bics[i] = bic\n\n\n\nfig, ax = plt.subplots(nrows=4, figsize=(8,4), sharex=True, dpi=100)\nax[0].scatter(time_delays, reconstruction_errors, color='r', alpha=0.6)\nax[0].set_ylabel('MSE')\n\nax[1].scatter(time_delays, ranks, color='r', alpha=0.6)\nax[1].set_ylabel('Number of\\nModes')\n\nax[2].scatter(time_delays, aics, color='r', alpha=0.6)\nax[2].set_ylabel('AIC')\n\nax[3].scatter(time_delays, bics, color='r', alpha=0.6)\nax[3].set_ylabel('BIC')\nax[3].set_xlabel('Time Delay ($h$)')\n\nplt.suptitle('DMD Time-Delay Grid Search')\nplt.tight_layout()\nplt.show()\n\n\n\nLooking at the results of our grid search, it appears as though all of our metrics of performance decrease as delay increases. This suggests that as the model becomes more complex, it is capturing more dynamics instead of just noise. We will use the minimum MSE to select the best delay, then using the optimal SVD threshold to reduce the dimensionality of the model further.\n\noptimal_delay = time_delays[reconstruction_errors.argmin()]\nprint(f'Best Time Delay: {optimal_delay}')\n\n\n\n# change time delay and svd threshold\ndmd.time_delay = optimal_delay\ndmd.svd_threshold = 'optimal'\n\n\n\n# refit the model\ndmd.fit(X_centered)\n\n\n\n# Reconstruct the original data\nX_hat = dmd.predict()\n\n\n\nNow lets take a look at our reconstruction:\n\nfig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8, 5), dpi=100, sharex=True, sharey=True)\n\naxs = axs.ravel()\nfor i, c in enumerate(['Oz', 'POz', 'O1', 'O2']):\n\n    axs[i].plot(t, X_centered[ssvep_chans_dict[c], :], color='k', alpha=0.3)\n    axs[i].plot(t, X_hat[ssvep_chans_dict[c], :], alpha=0.7)\n    axs[i].set_title(c)\n\n    if i > 1:\n        axs[i].set_xlabel('Time (ms)')\n\n    axs[i].set_ylabel(r'Voltage ($\\mu V$)')\n\nplt.tight_layout()\nplt.show()\n\n\n\nWe can see the model did a decent job at reconstructing the general shape of the activity across multiple electrodes, while also ignoring sharp amplitude impulses that could be reflective of noise.\n\nLets take a look at the DMD mode spectrum to get an idea of which oscillations are driving activity in this trial. We’ll compare this spectrum to a discrete fourier transform (DFT) that is a conventional approach for time-frequency analysis of EEG data\n\n# isolate unique modes caused by +/- eigenvalue pairs\nunique_mode_freqs, unique_idx = np.unique(np.round(dmd.mode_hz, 2), return_index=True)\nunique_modes = dmd.modes[:, unique_idx]\n\nunique_time_dynamics = dmd.time_dynamics[unique_idx, :]\n\n\n\n# Compute mode power (Brunton et al., 2016)\nmodes_power = np.diag(unique_modes.conj().T @ unique_modes)\n\n\n\nCompute DFT:\n\n# Time series length is massive so do Fs * 5\nNFFT = 250*5\n\n\n\n# Compute FFT\nspectra = np.fft.rfft(X_centered, NFFT, axis=-1) / nTime\n\n\n\n# Extract frequencies of interest\nfreqs = np.fft.rfftfreq(NFFT, 1/Fs)\nkeep_idx = np.arange(np.argmin(abs(freqs-1)), np.argmin(abs(freqs-65)))\n\nfreqs = freqs[keep_idx]\nspectra = spectra[:, keep_idx]\n\n\n\n# Compute power\npow = abs(spectra**2)\n\n\n\nfig, ax = plt.subplots(ncols=2, figsize=(8, 4), dpi=100)\n\nax[0].plot(unique_mode_freqs, np.log(modes_power.real))\nax[0].set_xlabel('Frequency (Hz)', fontsize=12)\nax[0].set_ylabel(r'$\\log(\\left\\| \\Phi \\right\\|_{2}^{2})$', fontsize=12)\nax[0].set_title('DMD Mode Power Spectrum', fontsize=14)\n\n#plt.xlim(-1, 61) \n\n# highlight stimulation frequency\nax[0].axvline(9, color='red', linestyle=':')\nax[0].axvline(11, color='red', linestyle=':')\nax[0].set_xlim(-0.5, 61)\n\n# Average power across all electrodes\nax[1].plot(freqs, np.log10(pow.mean(axis=0)))\nax[1].set_xlabel('Frequency (Hz)', fontsize=12)\nax[1].set_ylabel(r'Power (DB)', fontsize=12)\nax[1].axvline(9, color='red', linestyle=':', label='Stimulation Freq Window')\nax[1].axvline(11, color='red', linestyle=':')\nax[1].set_xlim(-0.5, 61)\nax[1].set_title('Chan. Average DFT Power Spectrum', fontsize=14)\nax[1].legend(frameon=False)\n\nplt.tight_layout()\nplt.show()\n\n\n\n# plot modes around 10 Hz over time\nmodes_of_interest_idx = np.argwhere((9 < unique_mode_freqs) & (unique_mode_freqs < 11))\n\nplt.figure(figsize=(7, 4))\nplt.plot(t, unique_time_dynamics[modes_of_interest_idx, :].real.mean(axis=0).squeeze(), color=[0.6, 0.05, 0.6, 0.6])\nplt.ylabel('Mode Amplitude')\nplt.xlabel('Time (ms)')\nplt.title('Average Temporal Dynamics of Modes Between 9-11 Hz')\nplt.show()\n\n\n\nBoth spectograms show a peak at the stimulation frequency of 10 Hz. Note, DMD yielded a mode with a frequence of 10.47 Hz, hence why it is shifted off-center in the \\pm 1 Hz window around the center stimulation frequency. Though these plots may look similar, its important to remember that DMD is estimating dominant modes based on the spatial correlations across channels, while DFT is computed independently for each channel and then averaged. Interestingly, DMD also yielded a dominant 6.47 Hz component with a larger magnitude than the stimulation frequency. This could be due to the use of hankelization to create more structure in the time-shifted matrices, or be an actual brain component. We would need the electrode position file and to plot the togopraphic distribution of the mode to determine whether it is signal or noise.\nLooking at the average temporal dynamics (i.e., product of the Vandermode matrix of DMD eigenvalues and mode amplitudes) for DMD modes with frequencies between 9-11 Hz, we see an initial sharp increase in amplitude at stimulus onset (0 ms) followed by three bursts with the largest ~2000 ms.\n\nNext lets focus on forecasting the data. Instead of fitting the model to the full trial, we will only fit it to the first 3000 ms. Then, we will forecast the last 1000 ms.\n\ntrain_end = abs(t-3000).argmin()\n\nX_train, X_test = X_centered[:, :train_end], X_centered[:, train_end:]\n\n\n\ndmd.svd_threshold = 0.99\n\n\n\nreconstruction_errors = np.zeros(nDelays)\nfor i in trange(nDelays):\n    dmd.time_delay = time_delays[i]\n\n    dmd.fit(X_train)\n    X_hat = dmd.predict(start=0, end=X_train.shape[-1]) # reconstruct initial sequence\n    mse = np.mean((X_train - X_hat)**2)\n\n    reconstruction_errors[i] = mse\n\n\n\n# Select the best delay\noptimal_delay = time_delays[reconstruction_errors.argmin()]\nprint(f'Best Time Delay: {optimal_delay}')\n\n\n\ndmd.time_delay = optimal_delay\ndmd.svd_threshold = 'optimal'\n\n\n\ndmd.fit(X_centered)\n\n\n\n# Reconstruct initial time series and forecast \nforecast = dmd.predict(start=0, end=len(t))\n\n\n\n# truncate to get just the forecasted time points\nforecast = forecast[:, train_end:]\n\n\n\nfig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 6), dpi=100, sharex=True, sharey=True)\n\naxs = axs.ravel()\nfor i, c in enumerate(['Oz', 'POz', 'O1', 'O2']):\n\n    axs[i].plot(t, X_centered[ssvep_chans_dict[c], :], color='k', alpha=0.3)\n    axs[i].plot(t[train_end:], forecast[ssvep_chans_dict[c], :], color='g', alpha=0.7)\n    axs[i].set_title(c)\n    axs[i].axvline(t[train_end], color='black', linestyle=':', label='Train End')\n\n    if i > 1:\n        axs[i].set_xlabel('Time (ms)')\n\n    axs[i].set_ylabel(r'Voltage ($\\mu V$)')\n\n    if i==3:\n        ax[i].legend(frameon=False)\n\nplt.tight_layout()\nplt.show()\n\n\n\nrmse = np.sqrt(((X_centered[:, train_end:] - forecast)**2).mean())\nprint(f'RMSE: {rmse:0.2f}')\n\n\n\nLooking at a the forecasts for posterior electrodes, we see that Extended DMD does a fairly decent job at predicting activity 2 seconds in the future with a RMSE of 0.76. It does fail to capture potentially meaninfuly fluctuations in activity, such as the sharp increase in amplitude ~4000 ms, but otherwise it tracks the core structure of the time series.\n\n","type":"content","url":"/dmd#implementing-dmd","position":13},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl2":"Summary"},"type":"lvl2","url":"/dmd#summary","position":14},{"hierarchy":{"lvl1":"Dynamic Mode Decomposition (DMD)","lvl2":"Summary"},"content":"\n\nDMD and its variants offer a powerful, data-driven framework for uncovering the dynamics of a complex time series. Unlike traditional methods that treat space and time separately, DMD identifies coupled spatiotemporal modes that are both interpretable and spectrally rich. Once these modes are identified, they form a generative model capable of forecasting the system’s trajectory.","type":"content","url":"/dmd#summary","position":15},{"hierarchy":{"lvl1":"Gate Recurrent Network (COMING SOON)"},"type":"lvl1","url":"/gru","position":0},{"hierarchy":{"lvl1":"Gate Recurrent Network (COMING SOON)"},"content":"","type":"content","url":"/gru","position":1},{"hierarchy":{"lvl1":"Introduction: Forecasting the Future Brain States"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Introduction: Forecasting the Future Brain States"},"content":"Time-series forecasting is a pillar of modern data science, spanning economics, meteorology, and neuroscience. The goal is simple yet ambitious: to predict the future state of a system based on historical observations and underlying dynamics.\n\nWe generally categorize forecasting approaches into two distinct schools:\n\nTraditional Statistical Methods: These models decompose a series into trends, seasonality, and cycles. They are highly interpretable but rely on strict assumptions:\n\nStationarity: The statistical properties (mean, variance) remain constant over time. (Note: Non-stationarity is actually when these change).\n\nLinearity: The assumption of a linear relationship between past and future states.\n\nIndependence: Model residuals must be uncorrelated.\n\nMachine & Deep Learning (DL) Methods: DL models, such as Transformers or GRUs, are “universal function approximators.” They excel at capturing complex, non-linear mappings without requiring the data to satisfy rigid statistical assumptions. Recent strides in sequence-to-sequence modeling have made DL highly competitive for both short-term and long-term horizons.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Introduction: Forecasting the Future Brain States","lvl2":"EEG"},"type":"lvl2","url":"/#eeg","position":2},{"hierarchy":{"lvl1":"Introduction: Forecasting the Future Brain States","lvl2":"EEG"},"content":"Electroencephalography (EEG) is a noninvasive method for measuring electrical potentials generated by synchronous post-synaptic neural activity. A hallmark of this neuroimaging method is that it has exceptional temporal resolution that enables the near real-time recording of cortical activity underlying cognition and behavior. EEG research has provided seminal insights into a wide variety of brain functions, including the processing of environmental stimuli and their internal representations, the execution of different motor movements, and the occurrence of abnormal neural activity (e.g., seizures). Although substantial work has been dedicated towards understanding the state of the brain in the moment, relatively little has focused on determining how this state will evolve in the future.","type":"content","url":"/#eeg","position":3},{"hierarchy":{"lvl1":"Introduction: Forecasting the Future Brain States","lvl2":"Forecasting Algorithms & Data"},"type":"lvl2","url":"/#forecasting-algorithms-data","position":4},{"hierarchy":{"lvl1":"Introduction: Forecasting the Future Brain States","lvl2":"Forecasting Algorithms & Data"},"content":"In the following sections, we will cover the theoretical background and application of the following forecasting algorithms:\n\nVector Autoregressive Integrated Moving Average (VARIMA)\n\nDynamic Mode Decomposition (DMD)\n\nTemporal Convolution Network (TCN)\n\nGated Recurrent Unit (GRU)\n\nTransformer\n\nSelective State Space Model (S6)\n\nFor our analyses, we will use an open-source dataset from \n\nGu et al., 2024. Briefly, this data was recorded using a 64 channel EEG cap while human subjects viewed visual stimuli on a computerized screen. Importantly, these stimuli were flickered at a rate between 1-60 Hz at increments of 1 Hz for five seconds to induce a steady state visual evoked response (SSEVP). SSEVPs are characterized by oscillations at the exact same frequency as the displayed visual stimulus, and are commonly used as input signals for brain computer-interfaces due to their high signal-to-noise ratio.\n\nLets get started!","type":"content","url":"/#forecasting-algorithms-data","position":5},{"hierarchy":{"lvl1":"Selective State Space Model (COMING SOON)"},"type":"lvl1","url":"/s6","position":0},{"hierarchy":{"lvl1":"Selective State Space Model (COMING SOON)"},"content":"","type":"content","url":"/s6","position":1},{"hierarchy":{"lvl1":"Temporal Convolution Network (COMING SOON)"},"type":"lvl1","url":"/tcn","position":0},{"hierarchy":{"lvl1":"Temporal Convolution Network (COMING SOON)"},"content":"","type":"content","url":"/tcn","position":1},{"hierarchy":{"lvl1":"Transformer (COMING SOON)"},"type":"lvl1","url":"/transformer","position":0},{"hierarchy":{"lvl1":"Transformer (COMING SOON)"},"content":"","type":"content","url":"/transformer","position":1},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)"},"type":"lvl1","url":"/varima","position":0},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)"},"content":"In this section, we forecast EEG data using a VARIMA model. A VARIMA model extends the univariate ARIMA framework to multiple interdependent time series, making it well-suited for multichannel EEG signals, where activity from one electrode is highly correlated with another.\n\n","type":"content","url":"/varima","position":1},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl3":"Background"},"type":"lvl3","url":"/varima#background","position":2},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl3":"Background"},"content":"A VARIMA model is a multivariate extension of the univariate ARIMA framework. It is used to model and forecast systems where multiple time series influence one another, such as activity measured across multiple EEG channels. The model consists of three hyperparameters:\n\nq, the order of the moving-average (MA) component\n\np, the order of the vector autoregressive (VAR) component\n\nd, the differencing order used to obtain stationarity\n\nLets break down each of these components to understand how they capture the dynamics within a set of time series. First, define y_t as a vector of EEG values across m channels at time t (i.e., y_t \\in \\mathbb{R}^m).\n\n","type":"content","url":"/varima#background","position":3},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"type":"lvl4","url":"/varima#moving-average-ma-component","position":4},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"content":"The vector MA component is crucial for understanding how brief, unobserved events, like a sudden cognitive shift or external stimulus, echo across different EEG channels over time. We model this echo using “shocks” or “innovations” that propogate through the system.","type":"content","url":"/varima#moving-average-ma-component","position":5},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Defining the model","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"type":"lvl5","url":"/varima#defining-the-model","position":6},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Defining the model","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"content":"The vector MA model delineates that y_t is a weighted linear combination of the current shock (\\epsilon_t) and the past q shocks. In simpler terms, the current EEG signal is predicted by the summation of the current and previous forecasting errors for the last q timesteps.\n\nHere is the core equation:y_t = \\mu + \\epsilon_t + \\sum_{k=1}^q \\Theta_k \\epsilon_{t-k} \\tag{1}\n\nwhere:\n\n\\epsilon_t: A vector representing the unpredictable, instantaneous shock occurring at time t. This is what drives the current change.\n\n\\Theta_k (echo matrix): An m \\times m matrix that captures how the shock from k time steps ago (\\epsilon_{t-k}) influences current activity. This matrix represents the spatial correlations in forecast error at timestep k.\n\n\\mu: is a vector containing the steady-state mean value for each EEG channel.","type":"content","url":"/varima#defining-the-model","position":7},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl6":"The Backshift Operator for Compact Notation","lvl5":"Defining the model","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"type":"lvl6","url":"/varima#the-backshift-operator-for-compact-notation","position":8},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl6":"The Backshift Operator for Compact Notation","lvl5":"Defining the model","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"content":"To make the equations cleaner, we use the Backshift Operator (B). This operator simply shifts a time series backward in time: B^k x_t = x_{t-k}.\n\nWe define the polynomial matrix \\Theta(B) that collects all of the echo matrices as:\\Theta(B) = \\sum_{k=1}^q \\Theta_k B^k\n\nUsing this, the compact representation of the model takes the form of:y_t = \\mu + (I + \\Theta(B))\\epsilon_t \\tag{2}\n\nwhere I is an identity matrix.","type":"content","url":"/varima#the-backshift-operator-for-compact-notation","position":9},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Model Mean and Autocovariance","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"type":"lvl5","url":"/varima#model-mean-and-autocovariance","position":10},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Model Mean and Autocovariance","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"content":"To fully understand the vector MA process, we need its statistical properties, specifically its mean, variance, and autocovariance. These depend entirely on the properties of the shock vector, \\epsilon_t.","type":"content","url":"/varima#model-mean-and-autocovariance","position":11},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl6":"Properties of the shock vector","lvl5":"Model Mean and Autocovariance","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"type":"lvl6","url":"/varima#properties-of-the-shock-vector","position":12},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl6":"Properties of the shock vector","lvl5":"Model Mean and Autocovariance","lvl4":"Moving-Average (MA) Component","lvl3":"Background"},"content":"The shocks are assumed to be a white noise process. They are independent and identically distributed (i.i.d.) and have no time structure:\\begin{align*}\n\\epsilon &\\overset{\\text{iid}} \\sim N(0, \\Sigma) \\\\\nE[\\epsilon_t \\epsilon_t^T] &= \\Sigma \\\\\n\\text{Cov(}\\epsilon_t, \\epsilon_{t+k}\\text{)} &= 0 \\qquad \\text{for } k \\neq 0\n\\end{align*}\n\nWhere \\Sigma is the covariance matrix of the shocks, telling us how large and related the instantaneous shocks are across the m channels.\n\nGiven these properties, the expected value of an MA(q) process is:\\begin{align*}\nE[y_t] &= \\mu + (I + \\Theta(B)) \\epsilon_t\\\\\n&= E[\\mu + (I + \\Theta(B) \\epsilon_t)] \\\\\n&= \\mu + \\sum_{k=0}^q \\Theta_k E[\\epsilon_{t-k}] \\\\\n&= \\mu\n\\end{align*}\n\nThe variance, \\Gamma_y(0), tells us the total amount of variation in each EEG channel at any given time t. We derive this by summing the variance contributions of all independent shocks from k=0 to q. Setting \\Theta_0 = I:\\begin{align*}\n\\text{Var}(y_t) = \\Gamma_y(0) &= \\text{Var}(\\mu + (I + \\Theta(B)) \\epsilon_t) \\\\\n&= \\text{Var}(\\sum_{k=0}^q \\Theta_k \\epsilon_{t-k}) \\\\\n&= \\sum_{k=0}^q \\Theta_k \\text{Var}(\\epsilon_{t-k}) \\Theta_k^T \\\\\n&= \\sum_{k=0}^q \\Theta_k \\Sigma \\Theta_k^T\n\\end{align*}\n\nSimilarly the autocovariance, which indicates how the EEG signal at time t is correlated with the EEG signal at a later time t+l where l is the lag, can be derived from:\\begin{align*}\n\\Gamma_y(l) &= \\text{Cov}(y_t, y_{t+l}) \\\\\n&= E[(\\mu + (I + \\Theta(B)) \\epsilon_t)(\\mu + (I + \\Theta(B)) \\epsilon_{t+l})^T] \\\\\n&= E[(\\sum_{k=0}^q \\Theta_i \\epsilon_{t-k})(\\sum_{j=0}^q \\Theta_j \\epsilon_{t+l-j})^T] \\\\\n&= E[(\\sum_{k=0}^q \\Theta_i \\epsilon_{t-k})(\\sum_{j=0}^q \\epsilon_{t+l-j}^T \\Theta_j^T)] \\\\\n&= \\sum_{k=0}^q \\sum_{j=0}^q \\Theta_i E[\\epsilon_{t-k} \\epsilon_{t+l-j}^T] \\Theta_j^T \\\\\n&= \\sum_{k=0}^{q-l} \\Theta_i \\Sigma \\Theta_{k+l}^T \\qquad \\text{for } 0 \\leq k \\leq q\n\\end{align*}\n\nKey Takeaway: For any lag l greater than q (the look back window), the autocovariance \\Gamma_y(l) is zero. This is the defining feature of the vector MA model: the impact of the past shocks completely dies out after q time steps.\n\n","type":"content","url":"/varima#properties-of-the-shock-vector","position":13},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"Autoregressive (VAR) Component","lvl3":"Background"},"type":"lvl4","url":"/varima#autoregressive-var-component","position":14},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"Autoregressive (VAR) Component","lvl3":"Background"},"content":"The VAR component models the most intuitive aspect of time series analysis: how the past activity of all EEG channels influences their present activity. Specifically, a VAR(p) model looks back over p time steps to predict the current EEG vector, y_t.","type":"content","url":"/varima#autoregressive-var-component","position":15},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Defining the VAR model","lvl4":"Autoregressive (VAR) Component","lvl3":"Background"},"type":"lvl5","url":"/varima#defining-the-var-model","position":16},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Defining the VAR model","lvl4":"Autoregressive (VAR) Component","lvl3":"Background"},"content":"Here is the core equation of a VAR(p) process:y_t = \\delta + \\sum_{j=1}^p \\Phi_j y_{t-j} + \\epsilon_t \\tag{3}\n\nwhere\n\n\\Phi_j (Influence matrix): An m \\times m matrix of coefficients that reflects the influence of the EEG signal at time t-j on every channel at the current time t. This is where the cross-channel dependence is captured.\n\n\\delta (Intercept): A constant vector ensuring the series fluctuates around its long-term mean.","type":"content","url":"/varima#defining-the-var-model","position":17},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Compact notation and the Mean-Adjusted intercept","lvl4":"Autoregressive (VAR) Component","lvl3":"Background"},"type":"lvl5","url":"/varima#compact-notation-and-the-mean-adjusted-intercept","position":18},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Compact notation and the Mean-Adjusted intercept","lvl4":"Autoregressive (VAR) Component","lvl3":"Background"},"content":"Just as with the MA model, we can simplify the structure using the backshift operator B and by defining the polynomial autoregressive operator \\Phi(B):\\Phi(B) = \\sum_{j=1}^p \\Phi_j B^j\n\nThis allows enables Equation (3) to be written in a more compact form:(I - \\Phi(B))\\, y_t = \\delta + \\epsilon_t \\tag{4}\n\nOut of convention, the autoregressive operator is typically placed on the left hand side to clarify the structure of the model and indicate that it acts on the observed value y_t.\n\nNote, the intercept term \\delta does not the represent the means of each time series, but rather is related to it. By taking the expected value of Equation (3) and assuming the process is stationary (i.e., E[y_t] = E[y_{t-j}] = \\mu), we can express \\delta in terms of \\mu:E[y_t] = E[\\delta + \\Phi(B)y_t + \\epsilon_t]\\\\\nE[y_t] = E[\\delta] + E[\\Phi(B)y_t] + E[\\epsilon_t] \\\\\n\\mu = \\delta + \\Phi(B)\\mu \\\\\n\\delta = \\mu - \\Phi(B)\\mu  \\\\\n\\delta = (I - \\Phi(B)) \\mu \\\\","type":"content","url":"/varima#compact-notation-and-the-mean-adjusted-intercept","position":19},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Model Mean and Autocovariance","lvl4":"Autoregressive (VAR) Component","lvl3":"Background"},"type":"lvl5","url":"/varima#model-mean-and-autocovariance-1","position":20},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Model Mean and Autocovariance","lvl4":"Autoregressive (VAR) Component","lvl3":"Background"},"content":"Assuming the process is stationary, the expected value of the Var(p) process is a constant vector \\mu. As seen above, the mean is a direct function of the intercept \\delta and the autoregressive coefficients \\Phi_j.\\begin{align*}\nE[y_t] = \\mu &= E[\\delta + \\Phi(B)y_t + \\epsilon_t] \\\\\n&= \\delta + E[\\sum_{j=1}^p \\Phi_j y_{t-j}] \\\\\n&= \\delta + \\sum_{j=1}^p \\Phi_j E[y_{t-j}] \\\\\n&= \\delta + \\sum_{j=1}^p \\Phi_j \\mu \\\\\n\\mu &= \\delta(I-\\sum_{j=1}^p \\Phi_j)^{-1}\n\\end{align*}\n\nThe variance, \\Gamma_y(0), of this process is given by:\\begin{align*}\n\\text{Var}(y_t) = \\Gamma_y(0) &= \\text{Var}(\\delta + \\Phi(B)y_t + \\epsilon_t) \\\\\n&= \\sum_{j=1}^{p} \\text{Var} (\\Phi_j y_{t-j}) + \\text{Var}(\\epsilon_t) \\\\\n&= \\sum_{j=1}^{p} \\Phi_j \\text{Var}(y_{t-j}) \\Phi_j^T + \\Sigma \\\\\n&= \\sum_{j=1}^{p} \\Phi_j \\Gamma_y(0) \\Phi_j^T + \\Sigma \\\\\n\\Gamma_y(0) &= \\Sigma(I-\\sum_{j=1}^{p} \\Phi_j \\Phi_j^T)^{-1}\n\\end{align*}\n\nNote, unlike the vector MA(q) model where the autocovariance cuts off sharply, the VAR(p) model has an autocovariance function that decays exponentially. This reflects the fact that the influence of a signal’s past never truly vanishes, it only fades over time.\n\n","type":"content","url":"/varima#model-mean-and-autocovariance-1","position":21},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"The VARMA Model","lvl3":"Background"},"type":"lvl4","url":"/varima#the-varma-model","position":22},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"The VARMA Model","lvl3":"Background"},"content":"While the VAR model captures the influence of past signals and the vector MA model captures the influence of past shocks, neither alone may be sufficient for highly complex data like multichannel EEG. Whatsmore, is that fitting each model independently to a complex time series may require higher order terms, which can be difficult to fit. However, when combined together, they form a more powerful VARMA model. By combining Equations (2) and (4), we arrive at the representation:(I - \\Phi(B))\\, y_t = \\delta + (I + \\Theta(B)) \\epsilon_t \\tag{5}","type":"content","url":"/varima#the-varma-model","position":23},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"Extending to VARIMA","lvl3":"Background"},"type":"lvl4","url":"/varima#extending-to-varima","position":24},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"Extending to VARIMA","lvl3":"Background"},"content":"","type":"content","url":"/varima#extending-to-varima","position":25},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Differencing Operator","lvl4":"Extending to VARIMA","lvl3":"Background"},"type":"lvl5","url":"/varima#differencing-operator","position":26},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Differencing Operator","lvl4":"Extending to VARIMA","lvl3":"Background"},"content":"A critical challenge in analyzing physiological data like EEG is that the time series is often non-stationary. This means its statistical properties (like the mean and variance) change over time, which violates the core assumptions of the standard VARMA model. To overcome this, we use a technique called differencing before fitting the model. This technique involves taking the consecutive difference between current and past time points from one another to stabilize the mean of the series. Applying d levels of differencing creates a new, stationary series, w_t:w_t = (1 - B)^d y_t \\tag{6}\n\nwhere d=1 (first order differencing) means w_t = y_t - y_{t-1}.","type":"content","url":"/varima#differencing-operator","position":27},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Defining the VARIMA Model","lvl4":"Extending to VARIMA","lvl3":"Background"},"type":"lvl5","url":"/varima#defining-the-varima-model","position":28},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl5":"Defining the VARIMA Model","lvl4":"Extending to VARIMA","lvl3":"Background"},"content":"Substituting this into the VARMA form yields the full VARIMA(p, d, q) model:\\underbrace{(I - \\Phi(B))}_{\\text{VAR($p$)}}\\underbrace{(1 - B)^d}_{\\text{Differencing Operator}} y_t = \\delta + \\underbrace{(I + \\Theta(B))}_{\\text{MA($q$)}} \\epsilon_t \\tag{7}\n\nThis formulation allows the VARIMA model to capture both temporal dynamics, which describe how the EEG signal evolves over time, and spatial interactions, which describe how activity flows across channels. As a result, it is well suited for forecasting complex, multichannel physiological data.\n\n","type":"content","url":"/varima#defining-the-varima-model","position":29},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"Model Assumptions","lvl3":"Background"},"type":"lvl4","url":"/varima#model-assumptions","position":30},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl4":"Model Assumptions","lvl3":"Background"},"content":"Like any advanced statistical framework, the VARIMA model relies on several fundamental assumptions. These principles are essential because they ensure the model is both mathematically sound (stable) and yields reliable, interpretable forecasts.\n\nLinearity: The influence of past values (y_{t-j}) and past shocks (\\epsilon_{t-k}) on the current signal (y_t) is assumed to be a simple weighted sum Equation (7). The parameter matrices \\Phi_j and \\Theta_k act purely as linear scaling factors.\n\nWhy it’s necessary: Linearity allows for closed-form solutions for properties like the mean and variance, making the model computationally tractable and easier to analyze.\n\nContextual Implication (EEG): If the true interactions between brain regions are highly non-linear (e.g., if one region’s influence only turns on after a specific threshold is reached), the VARIMA model will only capture a first-order approximation of the true dynamics.\n\nStationarity: After applying d levels of differencing to the observed time series y_t Equation (6), the resulting series w_t = (I - B)^d y_t must be stationary.\n\nWhy it’s necessary: If the series is non-stationary, statistical estimation techniques fail because parameters estimated from one segment of the data are not guaranteed to be valid for another segment.\n\nContextual Implication (EEG): EEG data often contains slow drifts or trends, making it non-stationary. The integration factor (d) in VARIMA is specifically used to stabilize the mean and covariance structure before the VARMA modeling begins.\n\nWhite Noise Innovations: The innovations \\epsilon_t must be a white noise process with no autocorrelation (i.e., \\text{Cov(}\\epsilon_t, \\epsilon_{t+k}\\text{)}=0) and constant covariance.\n-  Important Caveat: While there is no autocorrelation over time, the model does allow for instantaneous correlations across channels (off-diagonal elements in \\Sigma are non-zero). This is essential for multichannel data where several signals are shocked simultaneously by a common event.\n\nWhy it’s necessary: If the innovations are correlated over time, it implies that there is unexplained systematic structure left in the residuals, meaning the model is incomplete and its predictions are sub-optimal.\n\nStability (Causality) and Invertibility: The roots of the characteristic equation associated with the autoregressive operator (I - \\Phi(B)) and moving-average operator (I + \\Theta(B)) must lie outside the unit circle. This ensures the process is causal, meaning the current value y_t can be expressed as a converging linear combination of current and past shocks\n\nWhy it’s necessary: These conditions mathematically ensure two things. First, that the influence of a random shock fades to zero over time (preventing unstable, exploding forecasts). Second, that the model has a unique and identifiable representation, which is crucial for reliable parameter estimation.\n\n","type":"content","url":"/varima#model-assumptions","position":31},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl3":"Implementing VARIMA"},"type":"lvl3","url":"/varima#implementing-varima","position":32},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl3":"Implementing VARIMA"},"content":"\n\nNow that we have covered the principles and assumptions of the VARIMA model, lets see it in action. We are going to use the VARMAX class from the statsmodels package, which enables us to estimate a VAR, VMA, or VARMA model. The dataset we will be forecasting is EEG activity from an SSVEP study (Gu et al., 2014).\n\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.tsa.api import VARMAX, VAR\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf, ccf\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import trange\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport itertools\nfrom joblib import Parallel, delayed\n\n%matplotlib inline\n\n\n\n# load single subject from Gu et al., 2024 SSVEP experiment\n# Note, data has been downsampled to 250 Hz\ndata = np.load('../Data/Gu_et_al_2024_SSVEP_dataset/Data/data_s1_64_down.npy')\n\n\n\n# block x stimulation frequency x time x channels x conditions (i.e., modulation depths; low and high luminance ratios)\n# stimulation frequencies are from 1-60 in increments of 1 Hz\nnBlocks, nFreqs, nTime, nChans, nCons = data.shape\n\n# extract a single set of time series for 4 Hz stimulation\n# transpose to make channels x time\ntrial_idx = 10\nstim_idx = 3\nX = data[trial_idx, stim_idx, :, :, 1].T\n\n# SSVEPs are typically localized over the P-PO-O electrodes \nssvep_chan_names = ['Pz', 'PO5', 'PO3', 'POz', 'PO4', 'PO6', 'O1', 'Oz', 'O2']\nssvep_chans_idx = [48,54,55,56,57,58,61,62,63]\n\nssvep_chans_dict = dict(zip(ssvep_chan_names, ssvep_chans_idx))\n\n\n\n# construct time vector. Stimulation time is 5s, and epochs included 0.14s post stimulus offset\nFs = 250.\nt = np.arange(0, 5.14, 1/Fs) * 1000\n\n\n\nLets visualize the data to get a sense of any structures that might be present\n\nplt.figure(figsize=(7,4))\nplt.plot(t, X[ssvep_chans_dict['Oz'], :], color='k', alpha=0.5)\nplt.xlabel('Time (ms)')\nplt.ylabel(r'Voltage ($\\mu V$)')\nplt.title('Oz')\nplt.show()\n\n\n\nWe can clearly see that the data is non-stationary and includes a linear trend. Lets see at how the time series looks after applying a differencing transformation and performing a test for non-stationarity\n\n# define function for computing the n-th order difference\ndef nth_order_difference(X, n=1, axis=0):\n    for _ in range(n):\n        X = np.diff(X, axis=axis)\n    return X\n\n\n\nd = 1\nX_diff = nth_order_difference(X, n=d, axis=-1)\n\n\n\nplt.figure(figsize=(7,4))\nplt.plot(t[d:], X_diff[ssvep_chans_dict['Oz'], :], color='k', alpha=0.5)\nplt.xlabel('Time (ms)')\nplt.ylabel(r'Voltage ($\\mu V$)')\nplt.title(f'Oz Differenced d={d}')\nplt.show()\n\n\n\nA common approach for testing if a multivariate time series is non-stationary is to apply the Augmented Dickey-Fuller (ADF) test to each variable individually, so we will just check stationarity at the electrode visualized above for brevity. If the results of the ADF test fail to reject the null hypothesis, then the time series is non-stationary.\n\nadf_test = adfuller(X_diff[ssvep_chans_dict['Oz'], :], autolag='AIC')\nprint(f'p-value = {adf_test[1]:0.2e}')\nprint('Failed to reject null, time series is non-stationary') if adf_test[1] > 0.05 else print('Rejected null, time series is stationary')\n\n\n\nThe results of the differencing transform have yielded a non-stationary time series. Now lets look at the autocorrelation and partial autocorrelation plots to get a sense of what the order of the model might be. Since we are dealing with multivariate data, we will have to compute the cross correlation for all possible pairs of time series. Instead of visualizing the correlation at each lag for each pair, we will instead look at the first lag to have a significant correlation to get a rough idea of the spatial relationships:\n\ndef get_first_significant_lag(series1, series2, max_lags=20, is_pacf=False):\n    n_obs = len(series1)\n    conf_level = 1.96 / np.sqrt(n_obs)\n    \n    # Determine which function to use\n    if series1 is series2:\n        values = pacf(series1, nlags=max_lags) if is_pacf else acf(series1, nlags=max_lags)\n    else:\n        # Cross-correlation\n        values = ccf(series1, series2)[:max_lags+1]\n\n    # Find first lag (starting from 1 to ignore lag 0 correlation) where abs > CI\n    for lag, val in enumerate(values[1:], start=1):\n        if abs(val) > conf_level:\n            return lag\n    return 0 # No significant lag found\n\n\n\nlag_acf_mat = np.zeros((nChans, nChans))\nlag_pacf_mat = np.zeros((nChans, nChans))\nfor i in range(nChans):\n    for j in range(nChans):\n        lag_acf_mat[i, j] = get_first_significant_lag(X_diff[i, :], X_diff[j,:], 100)\n        lag_pacf_mat[i, j] = get_first_significant_lag(X_diff[i, :], X_diff[j,:], 100, is_pacf=True)\n\n\n\n# focus on off diagonals to get ccf\nunique_ccf_lags, ccf_lag_freqs = np.unique((lag_acf_mat-np.diag(lag_acf_mat)).ravel(), return_counts=True)\n\n\n\n# zero out lag 0 since we masked it\nccf_lag_freqs[unique_ccf_lags == 0] = 0\n\n\n\nfig, ax = plt.subplots(nrows=1, figsize=(10, 3), sharex=True, sharey=True)\nax.bar(unique_ccf_lags, np.log(ccf_lag_freqs), color='lightblue')\nax.set_ylabel('Log(Frequency)')\nax.set_xlabel('Lag')\n\nax.set_title('Distribution of First Significant Lag Cross-Corrleations')\n\nplt.show()\n\n\n\n\n\nprint(f'Electrode ACFs: {(np.diag(lag_acf_mat))}\\n')\nprint(f'Electrode PACFs: {np.diag(lag_acf_mat)}')\n\n\n\nWhen looking at the distribution of the first lags with a signficant cross-correlation, we see that a lag of 1 (y_t vs y_{t+1}) has the highest frequency. This is not suprising, considering that electrical activity is conducted across the scalp extremely quickly, hence the poor spatial resolution of EEG. Looking at the ACFs and PACFs along the diagonal, we see a similar result of 1-2 lags.\n\nA more refined approach is to use information criterion metrics, such as AIC and BIC, and perform a grid search over a range of p and q values to find an optimal model that balances parsimony and minimizing residuals. However, before we start fitting models we need to first address the issue of multicolinearity, which is prevalent in brain data. We will mitigate this by performing PCA to extract uncorrelated components. To reduce computational load when fitting the model, lets split it into a train and test set.\n\n# NOTE: VARIMA and PCA need data in shape n observations x k_features\nX_train, X_test = X_diff[:, :500], X_diff[:, 500:]\n\nX_train = X_train.T\nX_test = X_test.T\n\n\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_train)\n\npca = PCA(n_components=10) # keep small to decrease computation time\nX_pca = pca.fit_transform(X_scaled)\n\n\n\n# Create helper function to parallelize fitting a VARMAX model\ndef evaluate_VARMAX(order, data, maxiter=10, verbose=False):\n    try: \n        model = VARMAX(data, order=order, trend='c')\n        results = model.fit(maxiter=maxiter, disp=verbose)\n        return results.bic\n    except:\n        return float('inf')\n\n\n\nq_range = np.arange(0, 5) # MA terms\np_range = np.arange(1, 5) # AR terms\n\npdq = list(itertools.product(p_range, q_range))\n\n# Parallel processing\nmax_iter = 500\ninfo_criteria = Parallel(n_jobs=6)(delayed(evaluate_VARMAX)(order, X_pca, max_iter) for order in pdq)\n    \n\n\n\nvarima_fit_summary = pd.DataFrame({\n    'p': [x[0] for x in pdq],\n    'q': [x[1] for x in pdq ],\n    'bic': info_criteria\n})\n\nprint(varima_fit_summary.sort_values(by='bic').reset_index(drop=True))\n\n\n\nLooking at the results of our grid search, we see that an VARIMA model with an order of p=1, q=2, d=1 (since we only used a 1st order difference), yields the lowest BIC score. Note, often times you may encounter convergence or estimation warnings when trying to fit each model. Although the VARIMA model is superior to a single VAR or MA model in theory, in practice it is very difficult to estimate a stable model given that the MA component requires maximum likehood estimation. It can also be challenging to identify a single unique model that captures the dynamics within your data, since different combinations of hyperparameters can produce the same quality of fit. Furthermore, VARIMA models can take quite a bit of time to fit, hence our use of parallel processing to explore the parameter space.\n\nIn practice, the VAR model is much easier to estimate using ordinary least-squares. Whatsmore, a VARIMA model can be approximated by a VAR model as the latter increases in parameter count. This is because a VAR model is equivalent to an MA model with an infinite number of parameters, and vice versa. Let use the statsmodels function VAR, which has a built-in method for selecting the best model based on information scores:\n\npca2 = PCA(n_components=nChans) # increase number of components since VAR model is easier to fit\nX_pca2 = pca2.fit_transform(X_scaled)\nvar_model = VAR(X_pca2)\n\n\n\n# select the optimal model based information criterion\nlag_comparison = var_model.select_order(maxlags=6, trend='c')\nprint(lag_comparison.summary())\nprint(f'Best BIC lag: {lag_comparison.bic}')\n\n\n\nIn our previous VARMAX analysis, we were forced to limit our scope to a subset of PCA components due to the heavy computational tax of the Moving Average (MA) terms. However, by transitioning to a pure Vector Autoregression (VAR) approach, we gain significant efficiency. This allows us to fit the model to the full suite of PCA components, capturing a more holistic snapshot of the brain’s electrical activity.\n\nLooking at the grid search results, it is apparent that the best model according to BIC is an VAR(0). In other words, a model with a constant term for the intercept. In contrast, AIC, FPE, and HQIC all suggest that an VAR(6) fit the time series the best. Lets compare the forecasting power of the VARMA(1, 2) and VAR(6) models to determine which is the top performer. We’ll ignore the VAR(0) model since it just uses the average of the time series to generate forecasts, which is common to use in baseline comparisons to assess if the added complexity by a VAR model is justified.\n\n","type":"content","url":"/varima#implementing-varima","position":33},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl3":"Forecasting"},"type":"lvl3","url":"/varima#forecasting","position":34},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl3":"Forecasting"},"content":"\n\n# Fit VARMAX \nvarma_model = VARMAX(X_pca, order=(1, 2))\nvarma_results = varma_model.fit(maxiter=500)\n\n\n\n# Fit VAR(6)\nvar_6_model = VAR(X_pca2)\nvar_6_results = var_6_model.fit(6, trend=\"c\")\n\n\n\n# Set the forecasting horizon\nhorizon = 764\n\n\n\nvarma_forecasts = varma_results.forecast(steps=horizon)\n\n#Project back into original space\nvarma_forecasts_projected = pca.inverse_transform(varma_forecasts).T\n\n\n\nvar_6_forecasts = var_6_results.forecast(X_pca2, steps=horizon)\nvar_6_forecasts_projected = pca2.inverse_transform(var_6_forecasts).T\n\n\n\n# scale test data for plotting comparison\nX_test_scaled = scaler.transform(X_test).T\n\n\n\nplt.figure(figsize=(7,4))\nplt.plot(t[500:500+horizon], X_test_scaled[ssvep_chans_dict['Oz'], :horizon], color='k', label='Ground Truth', alpha=0.4)\nplt.plot(t[500:500+horizon], varma_forecasts_projected[ssvep_chans_dict['Oz'], :], color='r', label='VARMA(1,2)', linestyle='--', alpha=0.7)\nplt.plot(t[500:500+horizon], var_6_forecasts_projected[ssvep_chans_dict['Oz'], :], color='b', label='VAR(6)', linestyle='-.', alpha=0.3)\nplt.xlabel('Time (ms)')\nplt.ylabel(r'Voltage ($\\mu V$)')\nplt.legend(frameon=False)\nplt.title(f'Forecasts of Oz Differenced d={d}')\nplt.show()\n\n\n\nvarma_mae = abs(X_test_scaled[:, :horizon] - varma_forecasts_projected).mean()\nvar_6_mae = abs(X_test_scaled[:, :horizon] - var_6_forecasts_projected).mean()\n\nprint('Forecast MAE')\nfor model, metric in zip(['VARMA(1, 2)', 'VAR(6)'], [varma_mae, var_6_mae]):\n    print(f'{model}: {metric:0.3f}')\n\n\n\nQualitative inspection of the forecasts suggest that the VAR(6) is superior to the VARMA(1,2), since the former closesly matches ampltiude deflections earlier in the forecasting period while the latter predicts a constant value throughout. However, comparison of their mean absolute error (MAE) reveals that the VARMA(1,2) actually yields smaller forecasting error. Ultimately, we see that both methods struggle to generate long-term forecasts of EEG activity. This is because they assume that the relationship between time points is strictly linear, but it is well known that neural activity evolves in a non-linear fashion. Its likely that these models are only useful if the training data is constrained to a small window of activity (e.g., 25 ms) and they are used generate short-horizon forecasts (e.g., 1-3 future points).\n\n","type":"content","url":"/varima#forecasting","position":35},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl2":"Summary"},"type":"lvl2","url":"/varima#summary","position":36},{"hierarchy":{"lvl1":"Vector Autoregression Integrated Moving Average Model (VARIMA)","lvl2":"Summary"},"content":"VARIMA is a standard time-series analysis algorithm that combines the utility of VAR and MA models to decrease the number of parameters used to capture spatiotemporal dynamics and generate forecasts. In practice, though, estimating the VARIMA model is challegenging, and it is more practical to construct a VAR model that can approximate its fit. Within the context of forecasting EEG activity, both of these models suffer at generating long-term forecasts since they are unable to capture important non-linear dynamics.","type":"content","url":"/varima#summary","position":37}]}